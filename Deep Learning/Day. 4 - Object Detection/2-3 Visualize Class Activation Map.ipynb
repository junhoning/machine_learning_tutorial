{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/multi-label-classification-and-class-activation-map-on-fashion-mnist-1454f09f5925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'mnist_png/mnist_png/training/'\n",
    "test_dir = 'mnist_png/mnist_png/testing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "learning_rate = 0.01\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\June\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\June\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3))(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(0.25)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='same')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3))(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "# net = layers.Dropout(0.25)(net)\n",
    "\n",
    "net = layers.GlobalAveragePooling2D()(net)\n",
    "net = layers.Dense(num_classes, activation='softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "#     save_to_dir='out_images'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\June\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "  25/1875 [..............................] - ETA: 15:14 - loss: 2.3114 - acc: 0.0838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-08257cb59ce3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit_generator(train_generator,\n\u001b[0;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m                    )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m       \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[1;34m(output_generator, mode)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \u001b[1;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# Returning `None` will trigger looping to stop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=2000,\n",
    "                    epochs=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gap_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Visualize CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import Keras's functional api\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "path = 'mnist_png/mnist_png/training/0/1.png'\n",
    "image = np.array(Image.open(path).convert('L'))\n",
    "image = image.reshape((1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_size_h = 28\n",
    "train_img_size_w = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x2ef706bc780>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2ef706bc748>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2ef706bcb70>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2ef6956a5f8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2ef66a8dac8>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2ef706c2390>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x2ef706c2470>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2ef706c2160>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2ef707315f8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x2ef70747e10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x2ef70714390>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2ef70783a58>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x2ef707839b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2ef707a8fd0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 65,642\n",
      "Trainable params: 65,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gap_weights = model.layers[-1].get_weights()[0]\n",
    "gap_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2ef70783a58>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_model = Model(inputs=model.input, outputs=(model.layers[-3].output, model.layers[-1].output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 5, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, results = cam_model.predict(image)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "features_for_one_img = features[idx, :, :, :]\n",
    "features_for_one_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cam_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8ba6a4571604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcam_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cam_features' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the weights from the last layer\n",
    "gap_weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "# create a new model to output the feature maps and the predicted labels\n",
    "cam_model = Model(inputs=model.input, outputs=(model.layers[-3].output, model.layers[-1].output)) \n",
    "\n",
    "# make the prediction for a set of test images\n",
    "features, results = cam_model.predict(image)\n",
    "\n",
    "# check the prediction for 10 test images\n",
    "for idx in range(1):   \n",
    "    # get the feature map of the test image\n",
    "    features_for_one_img = features[idx, :, :, :]\n",
    "\n",
    "    # map the feature map to the original size\n",
    "    height_roomout = train_img_size_h / features_for_one_img.shape[0]\n",
    "    width_roomout = train_img_size_w / features_for_one_img.shape[1]\n",
    "    cam_features = sp.ndimage.zoom(features_for_one_img, (height_roomout, width_roomout, 1), order=2)\n",
    "        \n",
    "    # get the predicted label with the maximum probability\n",
    "    pred = np.argmax(results[idx])\n",
    "    \n",
    "    # prepare the final display\n",
    "    plt.figure(facecolor='white')\n",
    "    \n",
    "    # get the weights of class activation map\n",
    "    cam_weights = gap_weights[:, pred]\n",
    "\n",
    "    # create the class activation map\n",
    "    cam_output = np.dot(cam_features, cam_weights)\n",
    "    \n",
    "    plt.imshow(image[idx, :, :, 0], alpha=0.5)\n",
    "    plt.imshow(cam_output, cmap='jet', alpha=0.5)\n",
    "     \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
